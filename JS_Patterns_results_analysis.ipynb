{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9dWoHfzaZZ-"
      },
      "source": [
        "# **Results Analysis**\n",
        "\n",
        "Author: Artur Kasenõmmn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQg3pvkN4Kbp"
      },
      "source": [
        "# **Introduction**\n",
        "\n",
        "This notebook contains the data analysis for the bachelor's thesis \"Energy Matters: Evaluating JavaScript Asynchronous Patterns for Green Development.\" The thesis investigates whether different JavaScript asynchronous programming patterns (callbacks, promises, and async/await) have significant differences in energy consumption for the two test cases specified in the thesis.\n",
        "\n",
        "In this notebook we analyze the results from our experiments. We start by loading the CSV data files and organizing them into data structures. Then we test for data normality, and based on the results apply additional tests to determine if there are any significant differences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SPt2ojj5oDM"
      },
      "source": [
        "## **Imports**\n",
        "\n",
        "May need to install some additional libraries that aren't included in the default environment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXVzb09oDKB9",
        "outputId": "b247f3f5-ac33-45a2-b100-3f96b2d19004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-posthocs\n",
            "  Downloading scikit_posthocs-0.11.4-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from scikit-posthocs) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from scikit-posthocs) (1.15.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from scikit-posthocs) (0.14.4)\n",
            "Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from scikit-posthocs) (2.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from scikit-posthocs) (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from scikit-posthocs) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.20.0->scikit-posthocs) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.20.0->scikit-posthocs) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.20.0->scikit-posthocs) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scikit-posthocs) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scikit-posthocs) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scikit-posthocs) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scikit-posthocs) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scikit-posthocs) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scikit-posthocs) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scikit-posthocs) (3.2.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->scikit-posthocs) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.20.0->scikit-posthocs) (1.17.0)\n",
            "Downloading scikit_posthocs-0.11.4-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: scikit-posthocs\n",
            "Successfully installed scikit-posthocs-0.11.4\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-posthocs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oFwwfBM3R6xp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from scipy.stats import kruskal\n",
        "from scipy.stats import shapiro\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scikit_posthocs as sp\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FROZoH_oafKz"
      },
      "source": [
        "## **Load data**\n",
        "\n",
        "First we need to manually add all our CSV files to the notebook working directory. Then we read them into data structures organized by test case and pattern type, which makes it easier to analyze."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NsmmpsSYYwAY"
      },
      "outputs": [],
      "source": [
        "tc1_files = [\n",
        "  'callback_get_tc1_results.csv', 'promise_get_tc1_results.csv', 'asyncawait_get_tc1_results.csv',\n",
        "  'callback_post_tc1_results.csv', 'promise_post_tc1_results.csv', 'asyncawait_post_tc1_results.csv'\n",
        "]\n",
        "tc2_files = [\n",
        "  'callback_tc2_results.csv', 'promise_tc2_results.csv', 'asyncawait_tc2_results.csv'\n",
        "]\n",
        "\n",
        "tc1_data = {}\n",
        "tc2_data = {}\n",
        "\n",
        "for file in tc1_files:\n",
        "  pattern_parts = file.split('_')\n",
        "  pattern = pattern_parts[0] + '_' + pattern_parts[1]\n",
        "  tc1_data[pattern] = pd.read_csv(file)\n",
        "\n",
        "for file in tc2_files:\n",
        "  pattern = file.split('_')[0]\n",
        "  tc2_data[pattern] = pd.read_csv(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0SLnu7vGDHE"
      },
      "source": [
        "## **Data Cleaning**\n",
        "\n",
        "We did not need to clean the data. The experiment was set up so that all result files were created in a consistent format. This means missing or incorrect values were not expected. We also manually checked the files and confirmed that there are no missing values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqyfW3T2argN"
      },
      "source": [
        "## **Data Normality Test**\n",
        "\n",
        "We use the Shapiro-Wilk test with an alpha level of α = 0.05 to check whether the data follows a normal distribution. This helps us decide between parametric or non-parametric statistical tests for comparing the patterns later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BMUCjzhfauhU"
      },
      "outputs": [],
      "source": [
        "def perform_shapiro_wilk(data, metric):\n",
        "  results = {}\n",
        "  for pattern, df in data.items():\n",
        "    stat, p = shapiro(df[f'TIME_SECONDS' if metric == 'time' else 'ENERGY_JOULES'])\n",
        "    results[pattern] = {\n",
        "      'Statistic': f\"{stat:.3f}\",\n",
        "      'p-value': f\"{p:.3f}\",\n",
        "      'Normality': \"Normal\" if p > 0.05 else \"Not Normal\"\n",
        "    }\n",
        "  return results\n",
        "\n",
        "def display_normality_results(results, title):\n",
        "  print(title)\n",
        "  df = pd.DataFrame.from_dict(results, orient='index')\n",
        "  df.index.name = 'Pattern'\n",
        "  print(df)\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddcO4tnl6Jcf"
      },
      "source": [
        "### **TC1 Normality Test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wstNeRfD6Sue",
        "outputId": "0098cfdb-789f-4097-f1eb-9b08194764cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TC1, Energy Consumption Normality Test\n",
            "                Statistic p-value   Normality\n",
            "Pattern                                      \n",
            "callback_get        0.897   0.007  Not Normal\n",
            "promise_get         0.590   0.000  Not Normal\n",
            "asyncawait_get      0.899   0.008  Not Normal\n",
            "callback_post       0.936   0.071      Normal\n",
            "promise_post        0.855   0.001  Not Normal\n",
            "asyncawait_post     0.913   0.018  Not Normal\n",
            "\n",
            "\n",
            "TC1, Execution Time Normality Test\n",
            "                Statistic p-value   Normality\n",
            "Pattern                                      \n",
            "callback_get        0.811   0.000  Not Normal\n",
            "promise_get         0.865   0.001  Not Normal\n",
            "asyncawait_get      0.699   0.000  Not Normal\n",
            "callback_post       0.743   0.000  Not Normal\n",
            "promise_post        0.714   0.000  Not Normal\n",
            "asyncawait_post     0.592   0.000  Not Normal\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tc1_energy_normality = perform_shapiro_wilk(tc1_data, 'energy')\n",
        "display_normality_results(tc1_energy_normality, \"TC1, Energy Consumption Normality Test\")\n",
        "\n",
        "tc1_time_normality = perform_shapiro_wilk(tc1_data, 'time')\n",
        "display_normality_results(tc1_time_normality, \"TC1, Execution Time Normality Test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZrDEtiP6Wqm"
      },
      "source": [
        "### **TC2 Normality Test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsoqlFtn6bRv",
        "outputId": "1f80e0bf-e6c5-4968-9e00-3658024a7f63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TC2,  Energy Consumption Normality Test\n",
            "           Statistic p-value   Normality\n",
            "Pattern                                 \n",
            "callback       0.970   0.551      Normal\n",
            "promise        0.776   0.000  Not Normal\n",
            "asyncawait     0.958   0.271      Normal\n",
            "\n",
            "\n",
            "TC2, Execution Time Normality Test\n",
            "           Statistic p-value   Normality\n",
            "Pattern                                 \n",
            "callback       0.360   0.000  Not Normal\n",
            "promise        0.250   0.000  Not Normal\n",
            "asyncawait     0.974   0.663      Normal\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tc2_energy_normality = perform_shapiro_wilk(tc2_data, 'energy')\n",
        "display_normality_results(tc2_energy_normality, \"TC2,  Energy Consumption Normality Test\")\n",
        "\n",
        "tc2_time_normality = perform_shapiro_wilk(tc2_data, 'time')\n",
        "display_normality_results(tc2_time_normality, \"TC2, Execution Time Normality Test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiA2B5-V8T3e"
      },
      "source": [
        "### **Normality Test Results**\n",
        "\n",
        "Based on the normality test results, we can see that most of our data does not follow a normal distribution. Since most of our data doesn't follow normal distributions, we should use non-parametric statistical tests. We will use the Kruskal-Wallis test, which is a non-parametric test that compares medians across multiple groups without requiring normally distributed data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-9BpMQPa1lN"
      },
      "source": [
        "## **Statistical Comparison**\n",
        "\n",
        "In this section, we apply the Kruskal-Wallis test to determine if there are statistically significant differences in energy consumption and execution time between the three patterns. We perform this analysis separately for TC1 and TC2. In TC1 we do the test for both GET and POST request results separately. For each test, we find the test statistic, p-value, and whether the differences are statistically significant using an alpha level of α = 0.05."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "K_uQXkF_a5QF"
      },
      "outputs": [],
      "source": [
        "def perform_kruskal_wallis(data):\n",
        "  data_list = [df.values.flatten() for df in data.values()]\n",
        "  stat, p = kruskal(*data_list)\n",
        "  results = {\n",
        "    'Statistic': f\"{stat:.3f}\",\n",
        "    'p-value': f\"{p:.3f}\",\n",
        "    'Significant': \"No\" if p >= 0.05 else \"Yes\"\n",
        "  }\n",
        "  return results\n",
        "\n",
        "def display_kruskal_wallis_results(results, title):\n",
        "  print(title)\n",
        "  df = pd.DataFrame.from_dict(results, orient='index')\n",
        "  df.index.name = 'Metric'\n",
        "  print(df)\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf-RWTqV-z2h"
      },
      "source": [
        "### **TC1 Statistical Comparison**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jryrOI3g_PqW"
      },
      "source": [
        "**GET Requests**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0ooBD8v-4Lm",
        "outputId": "b7519f6f-b704-404d-abde-02cfff5c9a6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TC1, Energy Consumption Kruskal-Wallis Test (GET)\n",
            "       Statistic p-value Significant\n",
            "Metric                              \n",
            "Energy     7.028   0.030         Yes\n",
            "\n",
            "\n",
            "TC1, Execution Time Kruskal-Wallis Test (GET)\n",
            "       Statistic p-value Significant\n",
            "Metric                              \n",
            "Time       0.062   0.969          No\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tc1_energy_get_patterns = {k: v[['ENERGY_JOULES']] for k, v in tc1_data.items() if 'get' in k}\n",
        "tc1_energy_get_kruskal = perform_kruskal_wallis(tc1_energy_get_patterns)\n",
        "display_kruskal_wallis_results({'Energy': tc1_energy_get_kruskal}, \"TC1, Energy Consumption Kruskal-Wallis Test (GET)\")\n",
        "\n",
        "tc1_time_get_patterns = {k: v[['TIME_SECONDS']] for k, v in tc1_data.items() if 'get' in k}\n",
        "tc1_time_get_kruskal = perform_kruskal_wallis(tc1_time_get_patterns)\n",
        "display_kruskal_wallis_results({'Time': tc1_time_get_kruskal}, \"TC1, Execution Time Kruskal-Wallis Test (GET)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brqcCD1W_TiP"
      },
      "source": [
        "**POST Request**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMo9plXD_V4w",
        "outputId": "502e73bd-5eec-4ac7-d705-e57fe78884e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TC1, Energy Consumption Kruskal-Wallis Test (POST)\n",
            "       Statistic p-value Significant\n",
            "Metric                              \n",
            "Energy     6.732   0.035         Yes\n",
            "\n",
            "\n",
            "TC1, Execution Time Kruskal-Wallis Test (POST)\n",
            "       Statistic p-value Significant\n",
            "Metric                              \n",
            "Time       0.850   0.654          No\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tc1_energy_post_patterns = {k: v[['ENERGY_JOULES']] for k, v in tc1_data.items() if 'post' in k}\n",
        "tc1_energy_post_kruskal = perform_kruskal_wallis(tc1_energy_post_patterns)\n",
        "display_kruskal_wallis_results({'Energy': tc1_energy_post_kruskal}, \"TC1, Energy Consumption Kruskal-Wallis Test (POST)\")\n",
        "\n",
        "tc1_time_post_patterns = {k: v[['TIME_SECONDS']] for k, v in tc1_data.items() if 'post' in k}\n",
        "tc1_time_post_kruskal = perform_kruskal_wallis(tc1_time_post_patterns)\n",
        "display_kruskal_wallis_results({'Time': tc1_time_post_kruskal}, \"TC1, Execution Time Kruskal-Wallis Test (POST)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uO5drP2Z-9Bh"
      },
      "source": [
        "### **TC2 Statistical Comparison**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjkeJZGa_Gfr",
        "outputId": "582f1d62-c874-40d5-b548-be2be043b3a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TC2, Energy Consumption Kruskal-Wallis Test\n",
            "       Statistic p-value Significant\n",
            "Metric                              \n",
            "Energy     0.706   0.703          No\n",
            "\n",
            "\n",
            "TC2, Execution Time Kruskal-Wallis Test\n",
            "       Statistic p-value Significant\n",
            "Metric                              \n",
            "Time      44.927   0.000         Yes\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tc2_energy_kruskal_data = {pattern: df[['ENERGY_JOULES']] for pattern, df in tc2_data.items()}\n",
        "tc2_energy_kruskal = perform_kruskal_wallis(tc2_energy_kruskal_data)\n",
        "display_kruskal_wallis_results({'Energy': tc2_energy_kruskal}, \"TC2, Energy Consumption Kruskal-Wallis Test\")\n",
        "\n",
        "tc2_time_kruskal_data = {pattern: df[['TIME_SECONDS']] for pattern, df in tc2_data.items()}\n",
        "tc2_time_kruskal = perform_kruskal_wallis(tc2_time_kruskal_data)\n",
        "display_kruskal_wallis_results({'Time': tc2_time_kruskal}, \"TC2, Execution Time Kruskal-Wallis Test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oza5CxrnAFSm"
      },
      "source": [
        "### **Statistical Comparison Test Results**\n",
        "\n",
        "For TC1, we found significant differences in energy consumption between the three patterns for both GET requests (p = 0.030) and POST requests (p = 0.035). This suggests that the choice of asynchronous pattern has a significant impact on energy efficiency for TC1. However, we did not find significant differences in execution time for either GET requests (p = 0.969) or POST requests (p = 0.654), which tells us that all three patterns perform similarly in terms of execution time for TC1.\n",
        "\n",
        "For TC2, we observed the opposite pattern. We found no significant differences in energy consumption between the patterns (p = 0.703), suggesting that pattern choice doesn't significantly affect energy consumption for TC2. However, we did find significant differences in execution time (p < 0.001), which tells us that pattern choice does impacts execution time for TC2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hccRM84bBxAE"
      },
      "source": [
        "## **Post-hoc Analysis: Dunn's Test**\n",
        "\n",
        "Since the Kruskal-Wallis test revealed differences in energy consumption for TC1 and in execution time for TC2, we need to determine which patterns differ from each other. For this purpose, we will now conduct Dunn's test. Dunn's test makes pairwise comparisons between all three asynchronous patterns, so we can identify exactly which patterns perform significantly better or worse than others. Note that we do the Dunn's test only for these test case and metric combinations that were found to have significant differences in previous section, i.e. energy consumption for TC1 and execution time for TC2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JxpWASx3DW30"
      },
      "outputs": [],
      "source": [
        "def perform_dunn_test(data, metric, title):\n",
        "  print(f\"Dunn's Test - {title} - {metric.capitalize()}\")\n",
        "  data_list = [df[f'TIME_SECONDS' if metric == 'time' else 'ENERGY_JOULES'].values for df in data.values()]\n",
        "  labels_array = np.concatenate([[label] * len(d) for label, d in zip(list(data.keys()), data_list)])\n",
        "  df = pd.DataFrame({metric: np.hstack(data_list), 'pattern': labels_array})\n",
        "  with pd.option_context('display.float_format', '{:.3f}'.format):\n",
        "    posthoc_results = sp.posthoc_dunn(df, val_col=metric, group_col='pattern', p_adjust='bonferroni')\n",
        "    print(posthoc_results)\n",
        "  print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A09GcvJDe0h"
      },
      "source": [
        "### **TC1 Dunn's Test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-jepEVkDffS",
        "outputId": "f4bb78f2-4f3d-41dd-ed80-3a7f03d1ff4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dunn's Test - TC1, GET Requests - Energy\n",
            "                asyncawait_get  callback_get  promise_get\n",
            "asyncawait_get           1.000         0.027        0.282\n",
            "callback_get             0.027         1.000        1.000\n",
            "promise_get              0.282         1.000        1.000\n",
            "\n",
            "\n",
            "Dunn's Test - TC1, POST Requests - Energy\n",
            "                 asyncawait_post  callback_post  promise_post\n",
            "asyncawait_post            1.000          0.030         0.380\n",
            "callback_post              0.030          1.000         0.877\n",
            "promise_post               0.380          0.877         1.000\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tc1_energy_get_patterns_dunn = {k: v[['ENERGY_JOULES']] for k, v in tc1_data.items() if 'get' in k}\n",
        "perform_dunn_test(tc1_energy_get_patterns_dunn, 'energy', 'TC1, GET Requests')\n",
        "\n",
        "tc1_energy_post_patterns_dunn = {k: v[['ENERGY_JOULES']] for k, v in tc1_data.items() if 'post' in k}\n",
        "perform_dunn_test(tc1_energy_post_patterns_dunn, 'energy', 'TC1, POST Requests')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3_io7aXDf7a"
      },
      "source": [
        "### **TC2 Dunn's Test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLqfgNq1DgZa",
        "outputId": "5e6c6520-35da-405a-af36-e1a62ec1b793"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dunn's Test - TC2 - Time\n",
            "            asyncawait  callback  promise\n",
            "asyncawait       1.000     0.000    1.000\n",
            "callback         0.000     1.000    0.000\n",
            "promise          1.000     0.000    1.000\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tc2_time_kruskal_data_dunn = {pattern: df[['TIME_SECONDS']] for pattern, df in tc2_data.items()}\n",
        "perform_dunn_test(tc2_time_kruskal_data_dunn, 'time', 'TC2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZtQq1tdHzJm"
      },
      "source": [
        "### **Dunn's Test Results**\n",
        "\n",
        "For energy use in TC1, it looks like async/await uses a different amount of energy than callback (p = 0.027 for GET and p = 0.030 for POST). These p-values are less than 0.05, which is our cutoff for saying there's a statistically significant difference. The promise pattern's energy use wasn't clearly different from the other two for GET requests (p = 0.282 compared to async/await, and p = 1.000 compared to callback, both greater than 0.05). For the POST requests, promise also did not differ from async/await (p = 0.380) and callback (p = 0.877).\n",
        "\n",
        "When we look at TC2, the callback pattern acted quite differently. It had a significantly different execution time compared to both async/await (p < 0.001) and promise (p < 0.001). These p-values are much lower than 0.05, showing a strong difference. On the other hand, async/await and promise took about the same amount of time to finish in TC2 (p = 1.000).\n",
        "\n",
        "In summary, for energy consumption in TC1, the p-values show a statistically significant difference between async/await and callback. For execution time in TC2, the very low p-values show a significant difference between callback and both async/await and promise, while the high p-value shows no significant difference between async/await and promise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E2i6YlqLhgA"
      },
      "source": [
        "## **Descriptive Statistics**\n",
        "\n",
        "The Dunn's test identified where the significant differences are. What it did not tell us is what the differences are, i.e. which pattern has lower energy consumption or execution time. To determine that, we will now calculate descriptive statistics (mean, median, standard deviation, min, max) for each pattern and test case to understand the differences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ojh9FMv_Lmi-"
      },
      "outputs": [],
      "source": [
        "def calculate_descriptive_stats(series):\n",
        "  return {\n",
        "    'mean': series.mean(),\n",
        "    'median': series.median(),\n",
        "    'std': series.std(),\n",
        "    'min': series.min(),\n",
        "    'max': series.max()\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNDS1Wx-L5Za"
      },
      "source": [
        "### **TC1 Descriptive Statistics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or6kl-aWMT3n"
      },
      "source": [
        "**GET Request**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkPTsWmdL_jW",
        "outputId": "c002c92c-1cbe-4411-855a-8204446ba612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pattern: callback_get\n",
            "Energy (Joules):\n",
            "    mean: 3.180\n",
            "    median: 3.080\n",
            "    std: 0.428\n",
            "    min: 2.610\n",
            "    max: 4.550\n",
            "Time (Seconds):\n",
            "    mean: 1.260\n",
            "    median: 1.259\n",
            "    std: 0.003\n",
            "    min: 1.256\n",
            "    max: 1.271\n",
            "\n",
            "Pattern: promise_get\n",
            "Energy (Joules):\n",
            "    mean: 3.370\n",
            "    median: 3.180\n",
            "    std: 0.728\n",
            "    min: 2.820\n",
            "    max: 6.660\n",
            "Time (Seconds):\n",
            "    mean: 1.260\n",
            "    median: 1.259\n",
            "    std: 0.004\n",
            "    min: 1.256\n",
            "    max: 1.269\n",
            "\n",
            "Pattern: asyncawait_get\n",
            "Energy (Joules):\n",
            "    mean: 3.394\n",
            "    median: 3.305\n",
            "    std: 0.364\n",
            "    min: 2.850\n",
            "    max: 4.620\n",
            "Time (Seconds):\n",
            "    mean: 1.260\n",
            "    median: 1.259\n",
            "    std: 0.005\n",
            "    min: 1.254\n",
            "    max: 1.282\n"
          ]
        }
      ],
      "source": [
        "for pattern, df in tc1_data.items():\n",
        "  if 'get' in pattern:\n",
        "    print(f\"\\nPattern: {pattern}\")\n",
        "    print(\"Energy (Joules):\")\n",
        "    for stat, value in calculate_descriptive_stats(df['ENERGY_JOULES']).items():\n",
        "      print(f\"    {stat}: {value:.3f}\")\n",
        "\n",
        "    print(\"Time (Seconds):\")\n",
        "    for stat, value in  calculate_descriptive_stats(df['TIME_SECONDS']).items():\n",
        "      print(f\"    {stat}: {value:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49jGIg-FMZ5H"
      },
      "source": [
        "**POST Request**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2vJE2ppMdB1",
        "outputId": "59f11557-83cf-42c8-c8ca-841c7c98ada3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pattern: callback_post\n",
            "Energy (Joules):\n",
            "mean: 3.187\n",
            "median: 3.220\n",
            "std: 0.202\n",
            "min: 2.710\n",
            "max: 3.470\n",
            "Time (Seconds):\n",
            "mean: 1.260\n",
            "median: 1.260\n",
            "std: 0.004\n",
            "min: 1.257\n",
            "max: 1.273\n",
            "\n",
            "\n",
            "Pattern: promise_post\n",
            "Energy (Joules):\n",
            "mean: 3.270\n",
            "median: 3.310\n",
            "std: 0.336\n",
            "min: 2.820\n",
            "max: 4.510\n",
            "Time (Seconds):\n",
            "mean: 1.260\n",
            "median: 1.260\n",
            "std: 0.003\n",
            "min: 1.255\n",
            "max: 1.274\n",
            "\n",
            "\n",
            "Pattern: asyncawait_post\n",
            "Energy (Joules):\n",
            "mean: 3.383\n",
            "median: 3.340\n",
            "std: 0.297\n",
            "min: 2.850\n",
            "max: 4.190\n",
            "Time (Seconds):\n",
            "mean: 1.260\n",
            "median: 1.259\n",
            "std: 0.005\n",
            "min: 1.256\n",
            "max: 1.285\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for pattern, df in tc1_data.items():\n",
        "  if 'post' in pattern:\n",
        "    print(f\"Pattern: {pattern}\")\n",
        "    print(\"Energy (Joules):\")\n",
        "    for stat, value in calculate_descriptive_stats(df['ENERGY_JOULES']).items():\n",
        "      print(f\"{stat}: {value:.3f}\")\n",
        "\n",
        "    print(\"Time (Seconds):\")\n",
        "    for stat, value in calculate_descriptive_stats(df['TIME_SECONDS']).items():\n",
        "      print(f\"{stat}: {value:.3f}\")\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2OD2up5L_42"
      },
      "source": [
        "### **TC2 Descriptive Statistics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iip8F66sMAT-",
        "outputId": "c97984a2-fafb-4a19-fdfd-8c70bda6c2b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pattern: callback\n",
            "Energy (Joules):\n",
            "mean: 3.207\n",
            "median: 3.190\n",
            "std: 0.360\n",
            "min: 2.570\n",
            "max: 3.930\n",
            "Time (Seconds):\n",
            "mean: 1.246\n",
            "median: 1.241\n",
            "std: 0.017\n",
            "min: 1.238\n",
            "max: 1.311\n",
            "\n",
            "\n",
            "Pattern: promise\n",
            "Energy (Joules):\n",
            "mean: 3.301\n",
            "median: 3.105\n",
            "std: 0.585\n",
            "min: 2.630\n",
            "max: 5.300\n",
            "Time (Seconds):\n",
            "mean: 1.258\n",
            "median: 1.252\n",
            "std: 0.033\n",
            "min: 1.247\n",
            "max: 1.434\n",
            "\n",
            "\n",
            "Pattern: asyncawait\n",
            "Energy (Joules):\n",
            "mean: 3.268\n",
            "median: 3.350\n",
            "std: 0.316\n",
            "min: 2.750\n",
            "max: 3.830\n",
            "Time (Seconds):\n",
            "mean: 1.253\n",
            "median: 1.253\n",
            "std: 0.003\n",
            "min: 1.247\n",
            "max: 1.260\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for pattern, df in tc2_data.items():\n",
        "  print(f\"Pattern: {pattern}\")\n",
        "  print(\"Energy (Joules):\")\n",
        "  for stat, value in calculate_descriptive_stats(df['ENERGY_JOULES']).items():\n",
        "    print(f\"{stat}: {value:.3f}\")\n",
        "\n",
        "  print(\"Time (Seconds):\")\n",
        "  for stat, value in calculate_descriptive_stats(df['TIME_SECONDS']).items():\n",
        "    print(f\"{stat}: {value:.3f}\")\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-LmfhcHNR4-"
      },
      "source": [
        "### **Descriptive Statistics Results**\n",
        "\n",
        "Looking at the descriptive statistics for TC1, we notice that the callback pattern generally showed the lowest average energy consumption for both GET (around 3.18 J) and POST (around 3.19 J) requests. The median energy consumption for callback was also the lowest for GET requests (around 3.08 J).  The standard deviation for callback energy was also relatively low (around 0.43 J for GET and 0.20 J for POST). In contrast, the promise pattern had an average around 3.37 J for GET and 3.27 J for POST, with medians around 3.18 J for GET and 3.31 J for POST. The promise GET request results still had a higher standard deviation (0.73 J) and a wider range (2.82 J to 6.66 J), indicating more variability in its energy consumption for GET requests. The async/await pattern had averages around 3.39 J for GET and 3.38 J for POST, with medians around 3.305 J for GET and 3.34 J for POST.\n",
        "\n",
        "When it comes to execution time in TC1, the data gives a different result. The average (around 1.260 s for all patterns) and median (around 1.259 s for GET and around 1.260 s for POST) execution times for GET and POST requests were similar across all three asynchronous patterns.\n",
        "\n",
        "For TC2, the key difference appears to be execution time. The callback pattern showed a faster average (around 1.246 s) and median (around 1.241 s) execution time compared to both the promise pattern (average around 1.258 s, median around 1.252 s) and async/await pattern (average around 1.253 s, median around 1.253 s). The callback pattern also showed a larger standard deviation in time (0.017 s) and a wider range (1.238 s to 1.311 s) compared to async/await (standard deviation 0.003 s, range 1.247 s to 1.260 s), which shows more variability in callback's execution time for TC2. Promise had the highest standard deviation in time (0.033 s) and the widest range (1.247 s to 1.434 s). Interestingly, the promise and async/await patterns had quite similar average and median execution times in this scenario. Regarding energy consumption in TC2, the average energy consumption was similar across all three patterns (around 3.21 J for callback, 3.30 J for promise, and 3.27 J for async/await). The standard deviations were 0.36 J for callback, 0.58 J for promise, and 0.32 J for async/await.\n",
        "\n",
        "In summary, the descriptive statistics suggest that for TC1, callback tended to have the lowest average energy consumption for both GET and POST requests, and the lowest median energy consumption for GET requests. For POST requests, Promise showed a slightly higher average but also a higher median energy consumption compared to callback. All patterns performed similarly in terms of execution time in TC1. For TC2, callback stood out as having the lowest execution time, although with more variability. Energy consumption in TC2 did not show clear advantages for any specific pattern."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrLn7gbQ3Sx6"
      },
      "source": [
        "## **How big are the differences?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUhAjphP2H6T",
        "outputId": "1afdb383-0cbe-4f73-82ea-e1df9c3dcb8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TC1 - Energy Consumption:\n",
            "Asyncawait (GET) vs. Callback (GET): Asyncawait consumed 6.75% more energy.\n",
            "Asyncawait (POST) vs. Callback (POST): Asyncawait consumed 6.15% more energy.\n",
            "\n",
            "C2 - Execution Time:\n",
            "Promise vs. Callback: Promise took 1.01% longer.\n",
            "Asyncawait vs. Callback: Async/await took 0.56% longer.\n"
          ]
        }
      ],
      "source": [
        "def calculate_mean_values(data, metric):\n",
        "  mean_values = {}\n",
        "  for pattern, df in data.items():\n",
        "    mean_values[pattern] = df[f'TIME_SECONDS' if metric == 'time' else 'ENERGY_JOULES'].mean()\n",
        "  return mean_values\n",
        "\n",
        "def calculate_percentage_difference(value, baseline):\n",
        "  return ((value - baseline) / baseline) * 100\n",
        "\n",
        "\n",
        "# TC1 - Energy Consumption\n",
        "tc1_energy_means = calculate_mean_values(tc1_data, 'energy')\n",
        "\n",
        "print(\"\\nTC1 - Energy Consumption:\")\n",
        "callback_get_energy_mean = tc1_energy_means['callback_get']\n",
        "asyncawait_get_energy_diff = calculate_percentage_difference(tc1_energy_means['asyncawait_get'], callback_get_energy_mean)\n",
        "print(f\"Asyncawait (GET) vs. Callback (GET): Asyncawait consumed {asyncawait_get_energy_diff:.2f}% more energy.\")\n",
        "\n",
        "callback_post_energy_mean = tc1_energy_means['callback_post']\n",
        "asyncawait_post_energy_diff = calculate_percentage_difference(tc1_energy_means['asyncawait_post'], callback_post_energy_mean)\n",
        "print(f\"Asyncawait (POST) vs. Callback (POST): Asyncawait consumed {asyncawait_post_energy_diff:.2f}% more energy.\")\n",
        "\n",
        "# TC2 - Execution Time\n",
        "tc2_time_means = calculate_mean_values(tc2_data, 'time')\n",
        "\n",
        "print(\"\\nC2 - Execution Time:\")\n",
        "callback_time_mean = tc2_time_means['callback']\n",
        "promise_time_diff = calculate_percentage_difference(tc2_time_means['promise'], callback_time_mean)\n",
        "asyncawait_time_diff = calculate_percentage_difference(tc2_time_means['asyncawait'], callback_time_mean)\n",
        "print(f\"Promise vs. Callback: Promise took {promise_time_diff:.2f}% longer.\")\n",
        "print(f\"Asyncawait vs. Callback: Async/await took {asyncawait_time_diff:.2f}% longer.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y68-oVK3jBp"
      },
      "source": [
        "For TC1 energy consumption, async/await used approximately 6-7% more energy than callback for both GET and POST requests. For TC2 execution time, promise took about 1% longer than callback, and async/await took about 0.6% longer than callback.\n",
        "\n",
        "Even though our numbers show some statistical differences between the patterns, we need to think about whether these differences are actually large enough in a real-world situation. Choosing which pattern to use also depends on other things, like how easy the code is to write and understand, and how well it handles problems. We'll discuss more about these things and whether it's really worth using one pattern over another in the thesis."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}